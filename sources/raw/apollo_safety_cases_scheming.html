<!-- LAYOUT:HEADER -->
<!doctype html>
<html lang="en">
	<head>
      
      <script id="Cookiebot" src="https://consent.cookiebot.com/uc.js" data-cbid="7a6ef7c9-0e38-40ea-a2a6-bae2000edcc0" data-blockingmode="auto" type="text/javascript"></script>
      
     
      <!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KB4HJ9ZX');</script>
<!-- End Google Tag Manager -->

      
      <script data-cookieconsent="ignore">
      window.dataLayer = window.dataLayer || [];
	    function gtag() {
	         dataLayer.push(arguments);
	    }
	    gtag("consent", "default", {
	         ad_personalization: "denied",
	         ad_storage: "denied",
	         ad_user_data: "denied",
	         analytics_storage: "denied",
	         functionality_storage: "denied",
	         personalization_storage: "denied",
	         security_storage: "granted",
	         wait_for_update: 500,
	    });
	    gtag("set", "ads_data_redaction", true);
	    gtag("set", "url_passthrough", false);
</script>
		
		<meta charset="UTF-8">
		<meta name="theme-color" content="#FAFAFA">
		<meta name="copyright" content="(c) 2026 Apollo" />
		<meta name="apple-mobile-web-app-title" content="Apollo" />
		<meta name="format-detection" content="telephone=no" />

		<link rel="icon" type="image/png" href="https://www.apolloresearch.ai/t/assets/img/favicon-96x96.png" sizes="96x96" />
        <link rel="icon" type="image/svg+xml" href="https://www.apolloresearch.ai/t/assets/img/favicon.svg" />
        <link rel="shortcut icon" href="https://www.apolloresearch.ai/t/assets/img/favicon.ico" />
        <link rel="apple-touch-icon" sizes="180x180" href="https://www.apolloresearch.ai/t/assets/img/apple-touch-icon.png" />
        <meta name="apple-mobile-web-app-title" content="Apollo" />
        <link rel="manifest" href="https://www.apolloresearch.ai/t/assets/img/site.webmanifest" />
      
		
		<meta name="msapplication-TileColor" content="#FAFAFA">

		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

					<link rel="stylesheet" href="https://www.apolloresearch.ai/t/assets/css/plyr.css" />
		
		<link href="https://www.apolloresearch.ai/t/assets/css/global.css?ver=1.0.91" rel="stylesheet">

		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<!-- BLOCK:HEAD -->
		<meta name='robots' content='index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1' />

	<title>Towards Safety Cases For AI Scheming &#8211; Apollo Research</title>
	<meta name="description" content="Developers of frontier AI systems will face increasingly challenging decisions about whether their AI systems are safe enough to develop and deploy. One reason why systems may not be safe is if they engage in scheming, where AI systems hide their true capabilities and objectives and covertly pursue misaligned goals. In our new report, &quot;Towards evaluations-based safety cases for AI scheming&quot;, written in collaboration with researchers from the UK AI Safety Institute, METR, Redwood Research, and UC Berkeley, we sketch how developers of AI systems could make a structured rationale – &#039;a safety case&#039; – that an AI system is unlikely to cause catastrophic outcomes through scheming." />
	<link rel="canonical" href="https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/" />
	<meta property="og:locale" content="en_US" />
	<meta property="og:type" content="article" />
	<meta property="og:title" content="Towards Safety Cases For AI Scheming &#8211; Apollo Research" />
	<meta property="og:description" content="Developers of frontier AI systems will face increasingly challenging decisions about whether their AI systems are safe enough to develop and deploy. One reason why systems may not be safe is if they engage in scheming, where AI systems hide their true capabilities and objectives and covertly pursue misaligned goals. In our new report, &quot;Towards evaluations-based safety cases for AI scheming&quot;, written in collaboration with researchers from the UK AI Safety Institute, METR, Redwood Research, and UC Berkeley, we sketch how developers of AI systems could make a structured rationale – &#039;a safety case&#039; – that an AI system is unlikely to cause catastrophic outcomes through scheming." />
	<meta property="og:url" content="https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/" />
	<meta property="og:site_name" content="Apollo Research" />
	<meta property="article:modified_time" content="2025-11-18T10:44:16+00:00" />
	<meta property="og:image" content="https://www.apolloresearch.ai/u/2024/10/Group-6-2-scaled.png" />
	<meta property="og:image:width" content="2560" />
	<meta property="og:image:height" content="1280" />
	<meta property="og:image:type" content="image/png" />
	<meta name="twitter:card" content="summary_large_image" />
	<script type="application/ld+json" class="yoast-schema-graph">{"@context":"https://schema.org","@graph":[{"@type":"WebPage","@id":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/","url":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/","name":"Towards Safety Cases For AI Scheming &#8211; Apollo Research","isPartOf":{"@id":"https://www.apolloresearch.ai/#website"},"primaryImageOfPage":{"@id":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/#primaryimage"},"image":{"@id":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/#primaryimage"},"thumbnailUrl":"https://www.apolloresearch.ai/u/2024/10/Group-6-2-scaled.png","datePublished":"2024-10-31T10:26:40+00:00","dateModified":"2025-11-18T10:44:16+00:00","description":"Developers of frontier AI systems will face increasingly challenging decisions about whether their AI systems are safe enough to develop and deploy. One reason why systems may not be safe is if they engage in scheming, where AI systems hide their true capabilities and objectives and covertly pursue misaligned goals. In our new report, \"Towards evaluations-based safety cases for AI scheming\", written in collaboration with researchers from the UK AI Safety Institute, METR, Redwood Research, and UC Berkeley, we sketch how developers of AI systems could make a structured rationale – 'a safety case' – that an AI system is unlikely to cause catastrophic outcomes through scheming.","breadcrumb":{"@id":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/"]}]},{"@type":"ImageObject","inLanguage":"en-US","@id":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/#primaryimage","url":"https://www.apolloresearch.ai/u/2024/10/Group-6-2-scaled.png","contentUrl":"https://www.apolloresearch.ai/u/2024/10/Group-6-2-scaled.png","width":2560,"height":1280},{"@type":"BreadcrumbList","@id":"https://www.apolloresearch.ai/research/towards-safety-cases-for-ai-scheming/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://www.apolloresearch.ai/"},{"@type":"ListItem","position":2,"name":"Towards Safety Cases For AI Scheming"}]},{"@type":"WebSite","@id":"https://www.apolloresearch.ai/#website","url":"https://www.apolloresearch.ai/","name":"Apollo Research","description":"","publisher":{"@id":"https://www.apolloresearch.ai/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https://www.apolloresearch.ai/?s={search_term_string}"},"query-input":{"@type":"PropertyValueSpecification","valueRequired":true,"valueName":"search_term_string"}}],"inLanguage":"en-US"},{"@type":"Organization","@id":"https://www.apolloresearch.ai/#organization","name":"Apollo Research","url":"https://www.apolloresearch.ai/","logo":{"@type":"ImageObject","inLanguage":"en-US","@id":"https://www.apolloresearch.ai/#/schema/logo/image/","url":"https://www.apolloresearch.ai/u/2025/11/Apollo-logo-empty-background-black-text.png","contentUrl":"https://www.apolloresearch.ai/u/2025/11/Apollo-logo-empty-background-black-text.png","width":1600,"height":441,"caption":"Apollo Research"},"image":{"@id":"https://www.apolloresearch.ai/#/schema/logo/image/"}}]}</script>


<style type='text/css'>
img:is([sizes=auto i],[sizes^="auto," i]){contain-intrinsic-size:3000px 1500px}
/*# sourceURL=wp-img-auto-sizes-contain-inline-css */
</style>
<script type="text/javascript" src="https://www.apolloresearch.ai/wp-content/plugins/stop-user-enumeration/frontend/js/frontend.js" id="stop-user-enumeration-js" defer="defer" data-wp-strategy="defer"></script>
<link rel="icon" href="https://www.apolloresearch.ai/u/2025/07/cropped-favicon-32x32.png" sizes="32x32" />
<link rel="icon" href="https://www.apolloresearch.ai/u/2025/07/cropped-favicon-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon" href="https://www.apolloresearch.ai/u/2025/07/cropped-favicon-180x180.png" />
<meta name="msapplication-TileImage" content="https://www.apolloresearch.ai/u/2025/07/cropped-favicon-270x270.png" />

	<style type='text/css'>
h1:where(.wp-block-heading).has-background,h2:where(.wp-block-heading).has-background,h3:where(.wp-block-heading).has-background,h4:where(.wp-block-heading).has-background,h5:where(.wp-block-heading).has-background,h6:where(.wp-block-heading).has-background{padding:1.25em 2.375em}h1.has-text-align-left[style*=writing-mode]:where([style*=vertical-lr]),h1.has-text-align-right[style*=writing-mode]:where([style*=vertical-rl]),h2.has-text-align-left[style*=writing-mode]:where([style*=vertical-lr]),h2.has-text-align-right[style*=writing-mode]:where([style*=vertical-rl]),h3.has-text-align-left[style*=writing-mode]:where([style*=vertical-lr]),h3.has-text-align-right[style*=writing-mode]:where([style*=vertical-rl]),h4.has-text-align-left[style*=writing-mode]:where([style*=vertical-lr]),h4.has-text-align-right[style*=writing-mode]:where([style*=vertical-rl]),h5.has-text-align-left[style*=writing-mode]:where([style*=vertical-lr]),h5.has-text-align-right[style*=writing-mode]:where([style*=vertical-rl]),h6.has-text-align-left[style*=writing-mode]:where([style*=vertical-lr]),h6.has-text-align-right[style*=writing-mode]:where([style*=vertical-rl]){rotate:180deg}
/*# sourceURL=https://www.apolloresearch.ai/wp-includes/blocks/heading/style.min.css */
</style>
<style type='text/css'>
.wp-block-image>a,.wp-block-image>figure>a{display:inline-block}.wp-block-image img{box-sizing:border-box;height:auto;max-width:100%;vertical-align:bottom}@media not (prefers-reduced-motion){.wp-block-image img.hide{visibility:hidden}.wp-block-image img.show{animation:show-content-image .4s}}.wp-block-image[style*=border-radius] img,.wp-block-image[style*=border-radius]>a{border-radius:inherit}.wp-block-image.has-custom-border img{box-sizing:border-box}.wp-block-image.aligncenter{text-align:center}.wp-block-image.alignfull>a,.wp-block-image.alignwide>a{width:100%}.wp-block-image.alignfull img,.wp-block-image.alignwide img{height:auto;width:100%}.wp-block-image .aligncenter,.wp-block-image .alignleft,.wp-block-image .alignright,.wp-block-image.aligncenter,.wp-block-image.alignleft,.wp-block-image.alignright{display:table}.wp-block-image .aligncenter>figcaption,.wp-block-image .alignleft>figcaption,.wp-block-image .alignright>figcaption,.wp-block-image.aligncenter>figcaption,.wp-block-image.alignleft>figcaption,.wp-block-image.alignright>figcaption{caption-side:bottom;display:table-caption}.wp-block-image .alignleft{float:left;margin:.5em 1em .5em 0}.wp-block-image .alignright{float:right;margin:.5em 0 .5em 1em}.wp-block-image .aligncenter{margin-left:auto;margin-right:auto}.wp-block-image :where(figcaption){margin-bottom:1em;margin-top:.5em}.wp-block-image.is-style-circle-mask img{border-radius:9999px}@supports ((-webkit-mask-image:none) or (mask-image:none)) or (-webkit-mask-image:none){.wp-block-image.is-style-circle-mask img{border-radius:0;-webkit-mask-image:url('data:image/svg+xml;utf8,<svg viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg"><circle cx="50" cy="50" r="50"/></svg>');mask-image:url('data:image/svg+xml;utf8,<svg viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg"><circle cx="50" cy="50" r="50"/></svg>');mask-mode:alpha;-webkit-mask-position:center;mask-position:center;-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-size:contain;mask-size:contain}}:root :where(.wp-block-image.is-style-rounded img,.wp-block-image .is-style-rounded img){border-radius:9999px}.wp-block-image figure{margin:0}.wp-lightbox-container{display:flex;flex-direction:column;position:relative}.wp-lightbox-container img{cursor:zoom-in}.wp-lightbox-container img:hover+button{opacity:1}.wp-lightbox-container button{align-items:center;backdrop-filter:blur(16px) saturate(180%);background-color:#5a5a5a40;border:none;border-radius:4px;cursor:zoom-in;display:flex;height:20px;justify-content:center;opacity:0;padding:0;position:absolute;right:16px;text-align:center;top:16px;width:20px;z-index:100}@media not (prefers-reduced-motion){.wp-lightbox-container button{transition:opacity .2s ease}}.wp-lightbox-container button:focus-visible{outline:3px auto #5a5a5a40;outline:3px auto -webkit-focus-ring-color;outline-offset:3px}.wp-lightbox-container button:hover{cursor:pointer;opacity:1}.wp-lightbox-container button:focus{opacity:1}.wp-lightbox-container button:focus,.wp-lightbox-container button:hover,.wp-lightbox-container button:not(:hover):not(:active):not(.has-background){background-color:#5a5a5a40;border:none}.wp-lightbox-overlay{box-sizing:border-box;cursor:zoom-out;height:100vh;left:0;overflow:hidden;position:fixed;top:0;visibility:hidden;width:100%;z-index:100000}.wp-lightbox-overlay .close-button{align-items:center;cursor:pointer;display:flex;justify-content:center;min-height:40px;min-width:40px;padding:0;position:absolute;right:calc(env(safe-area-inset-right) + 16px);top:calc(env(safe-area-inset-top) + 16px);z-index:5000000}.wp-lightbox-overlay .close-button:focus,.wp-lightbox-overlay .close-button:hover,.wp-lightbox-overlay .close-button:not(:hover):not(:active):not(.has-background){background:none;border:none}.wp-lightbox-overlay .lightbox-image-container{height:var(--wp--lightbox-container-height);left:50%;overflow:hidden;position:absolute;top:50%;transform:translate(-50%,-50%);transform-origin:top left;width:var(--wp--lightbox-container-width);z-index:9999999999}.wp-lightbox-overlay .wp-block-image{align-items:center;box-sizing:border-box;display:flex;height:100%;justify-content:center;margin:0;position:relative;transform-origin:0 0;width:100%;z-index:3000000}.wp-lightbox-overlay .wp-block-image img{height:var(--wp--lightbox-image-height);min-height:var(--wp--lightbox-image-height);min-width:var(--wp--lightbox-image-width);width:var(--wp--lightbox-image-width)}.wp-lightbox-overlay .wp-block-image figcaption{display:none}.wp-lightbox-overlay button{background:none;border:none}.wp-lightbox-overlay .scrim{background-color:#fff;height:100%;opacity:.9;position:absolute;width:100%;z-index:2000000}.wp-lightbox-overlay.active{visibility:visible}@media not (prefers-reduced-motion){.wp-lightbox-overlay.active{animation:turn-on-visibility .25s both}.wp-lightbox-overlay.active img{animation:turn-on-visibility .35s both}.wp-lightbox-overlay.show-closing-animation:not(.active){animation:turn-off-visibility .35s both}.wp-lightbox-overlay.show-closing-animation:not(.active) img{animation:turn-off-visibility .25s both}.wp-lightbox-overlay.zoom.active{animation:none;opacity:1;visibility:visible}.wp-lightbox-overlay.zoom.active .lightbox-image-container{animation:lightbox-zoom-in .4s}.wp-lightbox-overlay.zoom.active .lightbox-image-container img{animation:none}.wp-lightbox-overlay.zoom.active .scrim{animation:turn-on-visibility .4s forwards}.wp-lightbox-overlay.zoom.show-closing-animation:not(.active){animation:none}.wp-lightbox-overlay.zoom.show-closing-animation:not(.active) .lightbox-image-container{animation:lightbox-zoom-out .4s}.wp-lightbox-overlay.zoom.show-closing-animation:not(.active) .lightbox-image-container img{animation:none}.wp-lightbox-overlay.zoom.show-closing-animation:not(.active) .scrim{animation:turn-off-visibility .4s forwards}}@keyframes show-content-image{0%{visibility:hidden}99%{visibility:hidden}to{visibility:visible}}@keyframes turn-on-visibility{0%{opacity:0}to{opacity:1}}@keyframes turn-off-visibility{0%{opacity:1;visibility:visible}99%{opacity:0;visibility:visible}to{opacity:0;visibility:hidden}}@keyframes lightbox-zoom-in{0%{transform:translate(calc((-100vw + var(--wp--lightbox-scrollbar-width))/2 + var(--wp--lightbox-initial-left-position)),calc(-50vh + var(--wp--lightbox-initial-top-position))) scale(var(--wp--lightbox-scale))}to{transform:translate(-50%,-50%) scale(1)}}@keyframes lightbox-zoom-out{0%{transform:translate(-50%,-50%) scale(1);visibility:visible}99%{visibility:visible}to{transform:translate(calc((-100vw + var(--wp--lightbox-scrollbar-width))/2 + var(--wp--lightbox-initial-left-position)),calc(-50vh + var(--wp--lightbox-initial-top-position))) scale(var(--wp--lightbox-scale));visibility:hidden}}
/*# sourceURL=https://www.apolloresearch.ai/wp-includes/blocks/image/style.min.css */
</style>
<style type='text/css'>
ol,ul{box-sizing:border-box}:root :where(.wp-block-list.has-background){padding:1.25em 2.375em}
/*# sourceURL=https://www.apolloresearch.ai/wp-includes/blocks/list/style.min.css */
</style>
<style type='text/css'>
.is-small-text{font-size:.875em}.is-regular-text{font-size:1em}.is-large-text{font-size:2.25em}.is-larger-text{font-size:3em}.has-drop-cap:not(:focus):first-letter{float:left;font-size:8.4em;font-style:normal;font-weight:100;line-height:.68;margin:.05em .1em 0 0;text-transform:uppercase}body.rtl .has-drop-cap:not(:focus):first-letter{float:none;margin-left:.1em}p.has-drop-cap.has-background{overflow:hidden}:root :where(p.has-background){padding:1.25em 2.375em}:where(p.has-text-color:not(.has-link-color)) a{color:inherit}p.has-text-align-left[style*="writing-mode:vertical-lr"],p.has-text-align-right[style*="writing-mode:vertical-rl"]{rotate:180deg}
/*# sourceURL=https://www.apolloresearch.ai/wp-includes/blocks/paragraph/style.min.css */
</style>
<style type='text/css'>
:root{--wp--preset--aspect-ratio--square: 1;--wp--preset--aspect-ratio--4-3: 4/3;--wp--preset--aspect-ratio--3-4: 3/4;--wp--preset--aspect-ratio--3-2: 3/2;--wp--preset--aspect-ratio--2-3: 2/3;--wp--preset--aspect-ratio--16-9: 16/9;--wp--preset--aspect-ratio--9-16: 9/16;--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgb(6,147,227) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgb(252,185,0) 0%,rgb(255,105,0) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgb(255,105,0) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgb(255, 255, 255), 6px 6px rgb(0, 0, 0);--wp--preset--shadow--crisp: 6px 6px 0px rgb(0, 0, 0);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flex{display: flex;}.is-layout-flex{flex-wrap: wrap;align-items: center;}.is-layout-flex > :is(*, div){margin: 0;}body .is-layout-grid{display: grid;}.is-layout-grid > :is(*, div){margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
/*# sourceURL=global-styles-inline-css */
</style>
</head>
	<body class="wp-singular research-template-default single single-research postid-473 wp-theme-theme towards-safety-cases-for-ai-scheming" x-data>
		<!-- Google Tag Manager (noscript) -->
		<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-KB4HJ9ZX"
		height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
		<!-- End Google Tag Manager (noscript) -->
	
      
		<!-- BLOCK:HEAD -->

	<header :class="{ open : $store.global.menu }">
  <div class="container">
    <div class="grid vcenter-xs">
      <div class="col-8-xs col-2-sm">
        <a class="logo" href="/" title="Apollo Research">
          <img src="https://www.apolloresearch.ai/t/assets/img/logo.svg" alt="Apollo Research">
        </a>
      </div>

      <div class="col-4-xs col-10-sm">
        <div class="menu" @click="$store.global.menu = ! $store.global.menu"><svg width="35" height="8" viewBox="0 0 35 8" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M8 1H26.5" stroke="#0D0D0D" stroke-linecap="round"/> <path d="M8 4H26.5" stroke="#0D0D0D" stroke-linecap="round"/> <path d="M8 7H26.5" stroke="#0D0D0D" stroke-linecap="round"/> </svg> <svg width="6" height="6" viewBox="0 0 6 6" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M0.87868 0.878644L5.12132 5.12128M0.87868 5.12128L5.12132 0.878645" stroke="#0D0D0D" stroke-linecap="round"/> </svg></div>
        <nav>
          <ul class="grid hend-sm">
                          <li><a href="https://www.apolloresearch.ai/team/" >Team</a></li>
                          <li><a href="https://www.apolloresearch.ai/research/" >Research</a></li>
                          <li><a href="https://www.apolloresearch.ai/blog/" >Blog</a></li>
                          <li><a href="https://www.apolloresearch.ai/press/" >Press</a></li>
                          <li><a href="https://www.apolloresearch.ai/careers/" >Careers</a></li>
                          <li><a href="https://www.apolloresearch.ai/contact/" >Contact</a></li>
                      </ul>
        </nav>
      </div>
    </div>
  </div>
</header>
	<div asscroll-container>
	  <div class="wrapper">
	    <main>

<!-- LAYOUT:HEADER --><!-- LAYOUT:MAIN -->

	
		<section class="page-top" x-data="view">
      <link href="https://www.apolloresearch.ai/t/assets/css/page-top.css?ver=1.0.91" rel="stylesheet">      <div class="container">
        <div class="grid">
          <div class="col-12-sm">
            <div class="blocks">
              <div class="grid">
                <div class="col-3-md">
                  <div class="date">31/10/2024</div>

                  
                </div>
                <div class="col-9-md">
                  <h1>Towards Safety Cases For AI Scheming</h1>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="article" x-data="view">
      <link href="https://www.apolloresearch.ai/t/assets/css/article.css?ver=1.0.91" rel="stylesheet">      <div class="container t--fade">
        <div class="grid" x-data="post">

          <div class="sidebar-wrapper">
            <div class="sidebar dropdown" x-ref="chapters" :class="{ 'open' : open, 'hide' : stages.length == 0 }">
              <div class="head" @click="open = ! open">Contents <svg width="10" height="5" viewBox="0 0 10 5" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M9 0.5L5.04171 4.5L1 0.5" stroke="#00342E" stroke-linecap="round" stroke-linejoin="round"/> </svg></div>
              <div class="inside">
                <ul>
                  <template x-for="(stage, index) in stages">
                    <li @click="scrollTo" :class="{ 'active': index == stages_index }">
                      <span x-text="stage.nodeName == 'OL' ? 'Footnotes' : stage.innerText"></span>
                      <span x-text="stage.nodeName == 'OL' ? 'Footnotes' : stage.innerText"></span>
                    </li>
                  </template>
                </ul>
              </div>
              <div class="progress"></div>
            </div>
          </div>

          <div class="col-4-md col-3-xmd" data-wrapper>

          </div>

          <div class="col-8-md col-6-xmd">
            <div class="text content">
              	
                            
              
<p><em>Read the full paper </em><a href="https://arxiv.org/abs/2411.03336" target="_blank" rel="noreferrer noopener"><em>here</em></a><em>.</em></p>



<p>Developers of frontier AI systems will face increasingly challenging decisions about whether their AI systems are safe enough to develop and deploy. One reason why systems may not be safe is if they engage in <em>scheming</em>, where AI systems hide their true capabilities and objectives and covertly pursue misaligned goals.</p>



<p>In our new report, <a href="https://arxiv.org/abs/2411.03336" target="_blank" rel="noreferrer noopener">&#8220;Towards evaluations-based safety cases for AI scheming&#8221;</a>, written in collaboration with researchers from the UK AI Safety Institute, METR, Redwood Research, and UC Berkeley, we sketch how developers of AI systems could make a structured rationale – &#8216;a safety case&#8217; – that an AI system is unlikely to cause catastrophic outcomes through scheming.</p>



<p>This work should be seen as an early step in advancing the state of the field. We think it currently lacks crucial details that would be required to make a strong safety case.</p>



<figure class="wp-block-image" id="yui_3_17_2_1_1755080714791_67"><img fetchpriority="high" decoding="async" width="2500" height="2059" src="https://www.apolloresearch.ai/u/2025/08/Temp402x28529.webp" alt="What a safety case for scheming might look like" class="wp-image-474" srcset="https://www.apolloresearch.ai/u/2025/08/Temp402x28529.webp 2500w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-350x288.webp 350w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-700x577.webp 700w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-768x633.webp 768w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-1536x1265.webp 1536w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-2048x1687.webp 2048w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-2000x1647.webp 2000w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-1200x988.webp 1200w, https://www.apolloresearch.ai/u/2025/08/Temp402x28529-150x124.webp 150w" sizes="(max-width: 2500px) 100vw, 2500px" /><figcaption class="wp-element-caption"><em>Figure 1.</em><br>A condensed version of an example safety case sketch, included in the report. Provided for illustration.</figcaption></figure>



<h2 class="wp-block-heading">Scheming and safety cases</h2>



<p>We use <em>scheming</em> as an umbrella term for cases when AI systems pursue misaligned goals covertly, hiding their true capabilities and objectives. For example, an AI system might act helpful during testing, while secretly engaging in harmful actions such as sabotage once deployed. Scheming has not been observed &#8220;in the wild&#8221; yet, however publicly available AI systems have behaved egregiously misaligned (<a href="https://www.lesswrong.com/posts/WkchhorbLsSMbLacZ/ai-1-sydney-and-bing" target="_blank" rel="noreferrer noopener">Mowshowitz, 2023</a>) and research has shown examples of AI systems engaging in deception, including pretending to be less capable than they are (<a href="https://arxiv.org/abs/2311.07590" target="_blank" rel="noreferrer noopener">Sheurer et al, 2023</a>, <a href="https://arxiv.org/abs/2405.01576" target="_blank" rel="noreferrer noopener">Järviniemi &amp; Hubinger, 2024</a>). We think that as AI systems become more capable, scheming will be a particularly risky behavior that could lead to loss of control over AI systems.</p>



<p>The present work is part of an emerging approach to justifying safety of general-purpose AI systems: <em>safety cases</em>, which provide structured arguments that deploying an AI system is unlikely to cause significant harm (<a href="https://arxiv.org/abs/2403.10462" target="_blank" rel="noreferrer noopener">Clymer et al, 2024</a>, <a href="https://www.aisi.gov.uk/work/safety-cases-at-aisi" target="_blank" rel="noreferrer noopener">Irving, 2024</a>, <a href="https://arxiv.org/abs/2410.21572" target="_blank" rel="noreferrer noopener">Buhl et al, 2024</a>). Similar to how nuclear power plant and aircraft developers make safety cases before deploying their systems, developers of highly-capable AI systems could use safety cases to demonstrate that their systems won&#8217;t cause catastrophic harm — whether through misuse, misalignment or scheming specifically. Making safety cases for general-purpose AI systems is nascent and presents numerous open research problems. We find that the possibility of scheming makes it even harder.</p>



<h2 class="wp-block-heading">Core arguments and challenges</h2>



<p>Our report proposes three core arguments that could be used in safety cases:</p>



<ul class="wp-block-list">
<li><strong>Scheming Inability:</strong> Showing that AI systems are not capable of scheming, for example because they do not realize that scheming can be strategically beneficial, or they make obvious mistakes when attempting to scheme.</li>



<li><strong>Harm Inability:</strong> Showing that AI systems are not capable of causing harm through scheming, such as sabotaging their developers&#8217; organizations, even without any attempts to control them.</li>



<li><strong>Harm Control:</strong> Demonstrating that control measures would prevent unacceptable outcomes even if systems intentionally attempted to subvert them.</li>
</ul>



<p>We also discuss how safety cases might be supported by evidence that an AI system is reasonably aligned with its developers, by using alignment evaluations or arguing that the training process itself is unlikely to lead to scheming.</p>



<p>To illustrate how these arguments work in practice, our report includes an example safety case sketch for a hypothetical AI system deployed internally by an AI developer organization.</p>



<p>Making these arguments requires evidence of satisfying multiple challenging assumptions &#8211; from showing that AI systems do not strategically underperform in capability evaluations, to showing that control measures remain effective over time. We provide initial ideas for how developers may try to satisfy these assumptions, but ultimately many of them are open problems that require significant additional research progress.</p>



<h2 class="wp-block-heading">Safety cases in the near future</h2>



<p>Our evaluation of frontier models like OpenAI&#8217;s o1-preview, described in its <a href="https://cdn.openai.com/o1-system-card-20240917.pdf" target="_blank" rel="noreferrer noopener">model card</a>, shows that some publicly available AI systems are now capable of basic scheming. However, this scheming is visible directly in model outputs and legible to humans (even if not shown to users) and thus could be monitored by AI developers.</p>



<p>We think near-future safety cases for frontier models will rely on three key pillars:</p>



<ol class="wp-block-list">
<li>Monitoring for scheming in model outputs, proven via red-teaming to be accurate and robust even if the AI systems intentionally try to evade it.</li>



<li>Demonstrating inability for scheming in an illegible way: showing that models are not capable of obfuscating their scheming reasoning to look benign and not capable of extensive latent reasoning without any intermediate legible outputs.</li>



<li>Demonstrating inability to cause harm while scheming. This includes standard dangerous capability evaluations like CBRN, cyber, autonomy, as well as behaviors unique to scheming, such as sabotage (<a href="https://www.anthropic.com/research/sabotage-evaluations" target="_blank" rel="noreferrer noopener">Benton et al, 2024</a>).</li>
</ol>



<p>If models become capable of scheming illegibly, safety cases would need interpretability techniques to be good enough to monitor scheming reasoning within model internals. Developing interpretability techniques for this purpose is an active but neglected area of research. As of yet, none of the existing techniques have been demonstrated to be robust enough to rest a safety case on.</p>



<p>At Apollo, we are working on evaluations and basic science that could help enable such safety cases.</p>
            </div>
          </div>

          <div class="col-3-xmd">
            <ol class="footnotes"></ol>
          </div>

        </div>
      </div>
    </section>

    
		
<!-- LAYOUT:MAIN -->
<!-- LAYOUT:FOOTER -->
</main>

	<footer>
  <div class="container">
    <div class="grid">
      <div class="col-12-sm">
        <div class="blocks">
          <div class="grid hspace-between-xs">
            <div class="left"><a href="/" title="Apollo Research"><svg width="16" height="17" viewBox="0 0 16 17" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M7.86 14.8789C5.93 14.8789 4.2 13.9589 3.09 12.5489L1.48 13.4189C2.91 15.3989 5.24 16.6989 7.86 16.6989C10.48 16.6989 12.83 15.3889 14.26 13.3789L12.65 12.5189C11.54 13.9589 9.81 14.8789 7.86 14.8789Z" fill="#1A1919"/> <path d="M13.93 8.79895C13.93 9.74895 13.71 10.6389 13.33 11.4389L14.93 12.2989C15.45 11.2489 15.75 10.0589 15.75 8.80895C15.74 4.65895 12.55 1.24895 8.51 0.918945V2.73895C11.55 3.04895 13.93 5.63895 13.93 8.77895V8.79895Z" fill="#1A1919"/> <path d="M1.81 8.79895C1.81 5.65895 4.19 3.06895 7.23 2.74895V0.918945C3.19 1.24895 0 4.64895 0 8.79895C0 10.0689 0.3 11.2689 0.83 12.3289L2.42 11.4689C2.04 10.6589 1.81 9.74895 1.81 8.79895Z" fill="#1A1919"/> </svg></a>

                                            <div class="copy">Apollo Research </div>
                              <div class="copy">EIN 93-4310599</div>
                              <div class="copy">EU Transparency Register #837878591690-80</div>
              
              <div class="visible-md">
                <div class="menus">
                  <div class="grid">
                    <ul class="vcenter-xs">
                      <li>        
                      <a href="https://x.com/apolloaievals" target="_blank" title="Twitter"><svg width="16" height="15" viewBox="0 0 16 15" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M12.6009 0.187744H15.0544L9.69434 6.31392L16 14.6503H11.0627L7.19566 9.59432L2.77087 14.6503H0.315951L6.04904 8.09763L0 0.187744H5.06262L8.55811 4.80908L12.6009 0.187744ZM11.7399 13.1818H13.0993L4.32392 1.57911H2.86506L11.7399 13.1818Z" fill="#5B5858"/> </svg></a>
                      </li>
                      <li>
                      <a href="https://www.linkedin.com/company/apollo-research-ai/?originalSubdomain=uk" target="_blank" title="LinkedIn"><svg width="16" height="17" viewBox="0 0 16 17" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M14.8156 0.418945H1.18125C0.528125 0.418945 0 0.93457 0 1.57207V15.2627C0 15.9002 0.528125 16.4189 1.18125 16.4189H14.8156C15.4688 16.4189 16 15.9002 16 15.2658V1.57207C16 0.93457 15.4688 0.418945 14.8156 0.418945ZM4.74687 14.0533H2.37188V6.41582H4.74687V14.0533ZM3.55938 5.3752C2.79688 5.3752 2.18125 4.75957 2.18125 4.0002C2.18125 3.24082 2.79688 2.6252 3.55938 2.6252C4.31875 2.6252 4.93437 3.24082 4.93437 4.0002C4.93437 4.75645 4.31875 5.3752 3.55938 5.3752ZM13.6344 14.0533H11.2625V10.3408C11.2625 9.45645 11.2469 8.31582 10.0281 8.31582C8.79375 8.31582 8.60625 9.28145 8.60625 10.2783V14.0533H6.2375V6.41582H8.5125V7.45957H8.54375C8.85938 6.85957 9.63438 6.2252 10.7875 6.2252C13.1906 6.2252 13.6344 7.80645 13.6344 9.8627V14.0533Z" fill="#5B5858"/> </svg></a>
                      </li>
                    </ul>
                    <ul>
                                              <li><a href="https://www.apolloresearch.ai/privacy-policy/">Privacy Policy</a></li>
                                              <li><a href="https://www.apolloresearch.ai/cookie-policy/">Cookie Policy</a></li>
                                          </ul>
                  </div>
                </div>
              </div>
            </div>
            <div class="right">
              <div class="grid hend-md">
                                                  <ul>
                                          <li><a href="https://www.apolloresearch.ai/team/">Team</a></li>
                                          <li><a href="https://www.apolloresearch.ai/research/">Research</a></li>
                                          <li><a href="https://www.apolloresearch.ai/blog/">Blog</a></li>
                                      </ul>
                                  <ul>
                                          <li><a href="https://www.apolloresearch.ai/press/">Press</a></li>
                                          <li><a href="https://www.apolloresearch.ai/careers/">Careers</a></li>
                                          <li><a href="https://www.apolloresearch.ai/contact/">Contact</a></li>
                                      </ul>
                              </div>
              <div class="hidden-md">
                <div class="menus">
                  <ul class="vcenter-xs">
                    <li>        
                    <a href="https://x.com/apolloaievals" target="_blank" title="Twitter"><svg width="16" height="15" viewBox="0 0 16 15" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M12.6009 0.187744H15.0544L9.69434 6.31392L16 14.6503H11.0627L7.19566 9.59432L2.77087 14.6503H0.315951L6.04904 8.09763L0 0.187744H5.06262L8.55811 4.80908L12.6009 0.187744ZM11.7399 13.1818H13.0993L4.32392 1.57911H2.86506L11.7399 13.1818Z" fill="#5B5858"/> </svg></a>
                    </li>
                    <li>
                    <a href="https://www.linkedin.com/company/apollo-research-ai/?originalSubdomain=uk" target="_blank" title="LinkedIn"><svg width="16" height="17" viewBox="0 0 16 17" fill="none" xmlns="http://www.w3.org/2000/svg"> <path d="M14.8156 0.418945H1.18125C0.528125 0.418945 0 0.93457 0 1.57207V15.2627C0 15.9002 0.528125 16.4189 1.18125 16.4189H14.8156C15.4688 16.4189 16 15.9002 16 15.2658V1.57207C16 0.93457 15.4688 0.418945 14.8156 0.418945ZM4.74687 14.0533H2.37188V6.41582H4.74687V14.0533ZM3.55938 5.3752C2.79688 5.3752 2.18125 4.75957 2.18125 4.0002C2.18125 3.24082 2.79688 2.6252 3.55938 2.6252C4.31875 2.6252 4.93437 3.24082 4.93437 4.0002C4.93437 4.75645 4.31875 5.3752 3.55938 5.3752ZM13.6344 14.0533H11.2625V10.3408C11.2625 9.45645 11.2469 8.31582 10.0281 8.31582C8.79375 8.31582 8.60625 9.28145 8.60625 10.2783V14.0533H6.2375V6.41582H8.5125V7.45957H8.54375C8.85938 6.85957 9.63438 6.2252 10.7875 6.2252C13.1906 6.2252 13.6344 7.80645 13.6344 9.8627V14.0533Z" fill="#5B5858"/> </svg></a>
                    </li>
                  </ul>
                  <div class="grid">
                    <ul>
                                              <li><a href="https://www.apolloresearch.ai/privacy-policy/">Privacy Policy</a></li>
                                              <li><a href="https://www.apolloresearch.ai/cookie-policy/">Cookie Policy</a></li>
                                          </ul>
                  </div>
                </div>
              </div>
              <div class="text-right">Designed by <a href="https://and-now.co.uk/" target="_blank">And–Now</a></div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</footer>
  </div>
  
</div>

	<script type="speculationrules">
{"prefetch":[{"source":"document","where":{"and":[{"href_matches":"/*"},{"not":{"href_matches":["/wp-*.php","/panel/*","/u/*","/wp-content/*","/wp-content/plugins/*","/t/*","/*\\?(.+)"]}},{"not":{"selector_matches":"a[rel~=\"nofollow\"]"}},{"not":{"selector_matches":".no-prefetch, .no-prefetch a"}}]},"eagerness":"conservative"}]}
</script>
        <script>
            // Do not change this comment line otherwise Speed Optimizer won't be able to detect this script

            (function () {
                const calculateParentDistance = (child, parent) => {
                    let count = 0;
                    let currentElement = child;

                    // Traverse up the DOM tree until we reach parent or the top of the DOM
                    while (currentElement && currentElement !== parent) {
                        currentElement = currentElement.parentNode;
                        count++;
                    }

                    // If parent was not found in the hierarchy, return -1
                    if (!currentElement) {
                        return -1; // Indicates parent is not an ancestor of element
                    }

                    return count; // Number of layers between element and parent
                }
                const isMatchingClass = (linkRule, href, classes, ids) => {
                    return classes.includes(linkRule.value)
                }
                const isMatchingId = (linkRule, href, classes, ids) => {
                    return ids.includes(linkRule.value)
                }
                const isMatchingDomain = (linkRule, href, classes, ids) => {
                    if(!URL.canParse(href)) {
                        return false
                    }

                    const url = new URL(href)
                    const host = url.host
                    const hostsToMatch = [host]

                    if(host.startsWith('www.')) {
                        hostsToMatch.push(host.substring(4))
                    } else {
                        hostsToMatch.push('www.' + host)
                    }

                    return hostsToMatch.includes(linkRule.value)
                }
                const isMatchingExtension = (linkRule, href, classes, ids) => {
                    if(!URL.canParse(href)) {
                        return false
                    }

                    const url = new URL(href)

                    return url.pathname.endsWith('.' + linkRule.value)
                }
                const isMatchingSubdirectory = (linkRule, href, classes, ids) => {
                    if(!URL.canParse(href)) {
                        return false
                    }

                    const url = new URL(href)

                    return url.pathname.startsWith('/' + linkRule.value + '/')
                }
                const isMatchingProtocol = (linkRule, href, classes, ids) => {
                    if(!URL.canParse(href)) {
                        return false
                    }

                    const url = new URL(href)

                    return url.protocol === linkRule.value + ':'
                }
                const isMatchingExternal = (linkRule, href, classes, ids) => {
                    if(!URL.canParse(href) || !URL.canParse(document.location.href)) {
                        return false
                    }

                    const matchingProtocols = ['http:', 'https:']
                    const siteUrl = new URL(document.location.href)
                    const linkUrl = new URL(href)

                    // Links to subdomains will appear to be external matches according to JavaScript,
                    // but the PHP rules will filter those events out.
                    return matchingProtocols.includes(linkUrl.protocol) && siteUrl.host !== linkUrl.host
                }
                const isMatch = (linkRule, href, classes, ids) => {
                    switch (linkRule.type) {
                        case 'class':
                            return isMatchingClass(linkRule, href, classes, ids)
                        case 'id':
                            return isMatchingId(linkRule, href, classes, ids)
                        case 'domain':
                            return isMatchingDomain(linkRule, href, classes, ids)
                        case 'extension':
                            return isMatchingExtension(linkRule, href, classes, ids)
                        case 'subdirectory':
                            return isMatchingSubdirectory(linkRule, href, classes, ids)
                        case 'protocol':
                            return isMatchingProtocol(linkRule, href, classes, ids)
                        case 'external':
                            return isMatchingExternal(linkRule, href, classes, ids)
                        default:
                            return false;
                    }
                }
                const track = (element) => {
                    const href = element.href ?? null
                    const classes = Array.from(element.classList)
                    const ids = [element.id]
                    const linkRules = [{"type":"extension","value":"pdf"},{"type":"extension","value":"zip"},{"type":"protocol","value":"mailto"},{"type":"protocol","value":"tel"}]
                    if(linkRules.length === 0) {
                        return
                    }

                    // For link rules that target an id, we need to allow that id to appear
                    // in any ancestor up to the 7th ancestor. This loop looks for those matches
                    // and counts them.
                    linkRules.forEach((linkRule) => {
                        if(linkRule.type !== 'id') {
                            return;
                        }

                        const matchingAncestor = element.closest('#' + linkRule.value)

                        if(!matchingAncestor || matchingAncestor.matches('html, body')) {
                            return;
                        }

                        const depth = calculateParentDistance(element, matchingAncestor)

                        if(depth < 7) {
                            ids.push(linkRule.value)
                        }
                    });

                    // For link rules that target a class, we need to allow that class to appear
                    // in any ancestor up to the 7th ancestor. This loop looks for those matches
                    // and counts them.
                    linkRules.forEach((linkRule) => {
                        if(linkRule.type !== 'class') {
                            return;
                        }

                        const matchingAncestor = element.closest('.' + linkRule.value)

                        if(!matchingAncestor || matchingAncestor.matches('html, body')) {
                            return;
                        }

                        const depth = calculateParentDistance(element, matchingAncestor)

                        if(depth < 7) {
                            classes.push(linkRule.value)
                        }
                    });

                    const hasMatch = linkRules.some((linkRule) => {
                        return isMatch(linkRule, href, classes, ids)
                    })

                    if(!hasMatch) {
                        return
                    }

                    const url = "https://www.apolloresearch.ai/wp-content/plugins/independent-analytics/iawp-click-endpoint.php";
                    const body = {
                        href: href,
                        classes: classes.join(' '),
                        ids: ids.join(' '),
                        ...{"payload":{"resource":"singular","singular_id":473,"page":1},"signature":"0cf0cb952f10b427bb67af6e066baa12"}                    };

                    if (navigator.sendBeacon) {
                        let blob = new Blob([JSON.stringify(body)], {
                            type: "application/json"
                        });
                        navigator.sendBeacon(url, blob);
                    } else {
                        const xhr = new XMLHttpRequest();
                        xhr.open("POST", url, true);
                        xhr.setRequestHeader("Content-Type", "application/json;charset=UTF-8");
                        xhr.send(JSON.stringify(body))
                    }
                }
                document.addEventListener('mousedown', function (event) {
                                        if (navigator.webdriver || /bot|crawler|spider|crawling|semrushbot|chrome-lighthouse/i.test(navigator.userAgent)) {
                        return;
                    }
                    
                    const element = event.target.closest('a')

                    if(!element) {
                        return
                    }

                    const isPro = false
                    if(!isPro) {
                        return
                    }

                    // Don't track left clicks with this event. The click event is used for that.
                    if(event.button === 0) {
                        return
                    }

                    track(element)
                })
                document.addEventListener('click', function (event) {
                                        if (navigator.webdriver || /bot|crawler|spider|crawling|semrushbot|chrome-lighthouse/i.test(navigator.userAgent)) {
                        return;
                    }
                    
                    const element = event.target.closest('a, button, input[type="submit"], input[type="button"]')

                    if(!element) {
                        return
                    }

                    const isPro = false
                    if(!isPro) {
                        return
                    }

                    track(element)
                })
                document.addEventListener('play', function (event) {
                                        if (navigator.webdriver || /bot|crawler|spider|crawling|semrushbot|chrome-lighthouse/i.test(navigator.userAgent)) {
                        return;
                    }
                    
                    const element = event.target.closest('audio, video')

                    if(!element) {
                        return
                    }

                    const isPro = false
                    if(!isPro) {
                        return
                    }

                    track(element)
                }, true)
                document.addEventListener("DOMContentLoaded", function (e) {
                    if (document.hasOwnProperty("visibilityState") && document.visibilityState === "prerender") {
                        return;
                    }

                                            if (navigator.webdriver || /bot|crawler|spider|crawling|semrushbot|chrome-lighthouse/i.test(navigator.userAgent)) {
                            return;
                        }
                    
                    let referrer_url = null;

                    if (typeof document.referrer === 'string' && document.referrer.length > 0) {
                        referrer_url = document.referrer;
                    }

                    const params = location.search.slice(1).split('&').reduce((acc, s) => {
                        const [k, v] = s.split('=');
                        return Object.assign(acc, {[k]: v});
                    }, {});

                    const url = "https://www.apolloresearch.ai/api/iawp/search";
                    const body = {
                        referrer_url,
                        utm_source: params.utm_source,
                        utm_medium: params.utm_medium,
                        utm_campaign: params.utm_campaign,
                        utm_term: params.utm_term,
                        utm_content: params.utm_content,
                        gclid: params.gclid,
                        ...{"payload":{"resource":"singular","singular_id":473,"page":1},"signature":"0cf0cb952f10b427bb67af6e066baa12"}                    };

                    if (navigator.sendBeacon) {
                        let blob = new Blob([JSON.stringify(body)], {
                            type: "application/json"
                        });
                        navigator.sendBeacon(url, blob);
                    } else {
                        const xhr = new XMLHttpRequest();
                        xhr.open("POST", url, true);
                        xhr.setRequestHeader("Content-Type", "application/json;charset=UTF-8");
                        xhr.send(JSON.stringify(body))
                    }
                });
            })();
        </script>
        

  	  <script src="https://www.apolloresearch.ai/t/assets/js/plyr.js"></script>
	
  <script defer src="https://www.apolloresearch.ai/t/assets/js/alpine.js"></script>
  <script src="https://www.apolloresearch.ai/t/assets/js/lib.js?ver=1.0.91"></script>
  <script src="https://www.apolloresearch.ai/t/assets/js/app.js?ver=1.0.91"></script>


	</body>
</html>
<!-- LAYOUT:FOOTER -->